{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe3c96-ce4c-4dd6-be79-94d1aef61824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613c577c-0549-499c-b198-d98e1c25ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "schools_df = pd.read_csv('Resources/schools_complete.csv')\n",
    "students_df = pd.read_csv('Resources/students_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e5bb3-05ba-4098-9e91-2954160b14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data sets\n",
    "merged_df = pd.merge(students_df, schools_df, on=\"school_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4091757b-f1cf-411b-86e4-32b8db6d67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate passing scores\n",
    "passing_math = merged_df['math_score'] >= 70\n",
    "passing_read = merged_df['reading_score'] >= 70\n",
    "passing_both = passing_math & passing_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7669975-9ef7-4ed2-bf2a-f64d09d7ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for passing statuses to the merged DataFrame\n",
    "merged_df['passing_math'] = passing_math\n",
    "merged_df['passing_reading'] = passing_read\n",
    "merged_df['passing_both'] = passing_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76e94e-d628-45ea-8384-0dc69c3f9c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by | metrics\n",
    "school_group = merged_df.groupby('school_name')\n",
    "percent_passing_math = school_group['passing_math'].mean() * 100\n",
    "percent_passing_read = school_group['passing_reading'].mean() * 100\n",
    "percent_overall_pass = school_group['passing_both'].mean() * 100\n",
    "school_budget = school_group['budget'].mean()\n",
    "students_per_school = school_group['Student ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f3403-7ffa-4449-8007-1bc3e36e8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first DataFrame \n",
    "school_summary_df = pd.DataFrame({\n",
    "    \"Total Students\": students_per_school,\n",
    "    \"Total School Budget\": school_budget,\n",
    "    \"Per Student Budget\": school_budget / students_per_school,\n",
    "    \"Average Math Score\": school_group['math_score'].mean(),\n",
    "    \"Average Reading Score\": school_group['reading_score'].mean(),\n",
    "    \"% Passing Math\": percent_passing_math,\n",
    "    \"% Passing Reading\": percent_passing_read,\n",
    "    \"% Overall Passing\": percent_overall_pass,\n",
    "    \"School Type\": school_group['type'].first()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664bc85d-bb58-4571-8e59-9e869eb25de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores by School Size\n",
    "size_bins = [0, 1000, 2000, 5000]\n",
    "labels = [\"Small (<1000)\", \"Medium (1000-2000)\", \"Large (2000-5000)\"]\n",
    "\n",
    "# Categorize\n",
    "school_summary_df['School Size'] = pd.cut(school_summary_df['Total Students'], bins=size_bins, labels=labels)\n",
    "\n",
    "# Group by school size\n",
    "grouped_by_size = school_summary_df.groupby('School Size', observed=True).mean(numeric_only=True)\n",
    "\n",
    "# Select columns\n",
    "size_summary = grouped_by_size[['Average Math Score', 'Average Reading Score', '% Passing Math', '% Passing Reading', '% Overall Passing']]\n",
    "\n",
    "# Print the results\n",
    "print(\"Scores by School Size:\")\n",
    "print(size_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66152898-5ddd-41f7-807c-4c3987b0a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores by School Spending\n",
    "\n",
    "# Define spending bins and labels\n",
    "spending_bins = [0, 585, 630, 645, 680]\n",
    "labels = [\"<$585\", \"$585-630\", \"$630-645\", \"$645-680\"]\n",
    "\n",
    "# Categorize \n",
    "school_summary_df['Spending Ranges (Per Student)'] = pd.cut(school_summary_df['Per Student Budget'], bins=spending_bins, labels=labels)\n",
    "\n",
    "# Group by spending range\n",
    "grouped_by_spending = school_summary_df.groupby('Spending Ranges (Per Student)', observed=True).mean(numeric_only=True)\n",
    "\n",
    "# Create DataFrame to hold the above results\n",
    "spending_summary = pd.DataFrame({\n",
    "    \"Average Math Score\": grouped_by_spending[\"Average Math Score\"],\n",
    "    \"Average Reading Score\": grouped_by_spending[\"Average Reading Score\"],\n",
    "    \"% Passing Math\": grouped_by_spending[\"% Passing Math\"],\n",
    "    \"% Passing Reading\": grouped_by_spending[\"% Passing Reading\"],\n",
    "    \"% Overall Passing\": grouped_by_spending[\"% Overall Passing\"]\n",
    "})\n",
    "\n",
    "# Print output\n",
    "print(\"Scores by Spending:\")\n",
    "print(spending_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff68f5-9747-4bbc-8b82-8935beadfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest-Performing Schools (by % Overall Passing)\n",
    "# Sort schools using sort_values % 'Overall Passing' | descending | display the top 5\n",
    "top_schools = school_summary_df.sort_values('% Overall Passing', ascending=False).head(5)\n",
    "print(\"\\nTop Schools:\")\n",
    "print(top_schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be59579-2403-4915-bdad-3b636c2d1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowest-Performing Schools (by % Overall Passing) - just ascend instead of descend through the data\n",
    "# Sort schools using sort_values % 'Overall Passing' | ascending | display the top 5\n",
    "bottom_schools = school_summary_df.sort_values('% Overall Passing', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7dbdf-97c6-4328-bbaa-7d97c1a35b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math Scores \n",
    "# Group by school | name | grade | average math scores - add .head() to pull smaller data set\n",
    "math_scores = merged_df.pivot_table(index='school_name', columns='grade', values='math_score', aggfunc='mean').head()\n",
    "\n",
    "# Math Scores by Grade\n",
    "math_scores = math_scores[['9th', '10th', '11th', '12th']]\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"\\nMath Scores by Grade:\")\n",
    "print(math_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe5878-2f5f-4ec2-ab44-f40ac1f856d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Scores \n",
    "reading_scores = merged_df.pivot_table(index='school_name', columns='grade', values='reading_score', aggfunc='mean').head()\n",
    "\n",
    "# Sort columns \n",
    "reading_scores = reading_scores[['9th', '10th', '11th', '12th']]\n",
    "\n",
    "# Print the DataFrame - add .head() to pull smaller data set - I then separated the outputs with \\n to make it more readable\n",
    "print(\"\\nReading Scores by Grade:\")\n",
    "print(reading_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7312ab-7ef3-4906-adf9-4c0ad3603d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create type_summary DataFrame\n",
    "type_summary = school_summary_df.groupby('School Type').mean(numeric_only=True)[[\n",
    "    \"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"\n",
    "]]\n",
    "\n",
    "# Print type_summary\n",
    "print(\"\\nSummary by School Type:\")\n",
    "print(type_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789caaa3-b778-4a46-ab2d-a66ea0663d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
